 <!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Parallelizing Alpha-Beta Pruning of Othello Game Decision Trees by xcindylin</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section id="top" class="page-header">
      <h1 class="project-name">Parallelizing Alpha-Beta Pruning of Othello Game Decision Trees</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/xcindylin/CS179-Project" class="btn">View on GitHub</a>
      <a href="https://github.com/xcindylin/CS179-Project/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/xcindylin/CS179-Project/tarball/master" class="btn">Download .tar.gz</a>
      <h3>Quick Navigation:</h3>
      <a href="#summary" class="btn">Summary</a>
      <a href="#background" class="btn">Background</a>
      <a href="#approach" class="btn">Approach</a>
      <a href="#optimizations" class="btn">Optimizations</a>
      <a href="#gpu-speedup" class="btn">GPU Speedup Full Results</a>
    </section>

    <section class="main-content">
      <h2>
      <a id="summary" class="anchor" href="#summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary</h2>
      <p>The last time we worked together on a project was when we were freshmen in CS 2, writing an alpha-beta pruning algorithm to play Othello for the final tournament of the class. Our algorithm was pretty good, but not great - it ended up maybe 10th out of about 50, and one of our biggest problems was that if we tried to increase our search depth, we would run out of computation time. We decided to try to parallelize the algorithm using the GPU and compare its performance to the serialized version on several different board sizes.</p>

      <h6 align="right"><a href="#top">Back to Top</a></h6>

      <h2>
      <a id="background" class="anchor" href="#background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h2>
      <p>Games like Othello, Chess, and Go have not yet been solved due to their high complexity, and in addition most decision trees used to play these games cannot search to very high depths because of the games’ high branching factors. The <a href="http://en.wikipedia.org/wiki/Minimax">minimax algorithm</a>, which generates a complete decision tree down to a specified depth, is an example of one such algorithm. <a href="http://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning">Alpha-beta pruning</a> is a technique built on top of minimax that is used to minimize the number of branches to be searched by determining which branches will have no effect on the outcome anyway, and “pruning” these away. Even with alpha-beta pruning, though, search depths are still very limited, as the time needed to run the algorithm increases by approximately one order of magnitude for every 1-level increase in depth. Thus, we thought that it might be interesting to see if we could parallelize the algorithm to make it run faster. Because the decision tree generated is huge and has many nodes to search through, dividing up the work between multiple threads seemed like a promising way to speed up the computation.</p>

      <p>However, there are aspects to alpha-beta pruning that pose particular challenges to parallelization on the GPU. The search is performed depth-first, and results from earlier branches are used to determine whether later ones should be examined or not. Parallelizing necessarily sacrifices some of this information, since if we want to search multiple branches in parallel those branches don’t have the bounds from each other to work with. Because of this, we may actually end up searching branches that would’ve been pruned in the serialized version. In theory, a thread searching one branch could update the other threads with its bounds when it finishes, but in practice this is difficult to implement on the GPU as it would require blocks to be able to break other blocks out of recursive function calls.</p>

      <h6 align="right"><a href="#top">Back to Top</a></h6>

      <h2>
      <a id="approach" class="anchor" href="#approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Approach</h2>
      <p>In spite of the aforementioned difficulties, we decided to attempt to parallelize and optimize the alpha-beta pruning algorithm because we were curious to see whether it would still be faster than the serialized version, and if so, by how much. Although this isn’t likely to be a massively parallelizable application (such as matrix transpose, for instance) we thought it would still be interesting to see what kind of performance improvements we could make. We first implemented the standard serialized alpha-beta pruning algorithm (built on top of a basic Othello board implementation from CS 2), along with a heuristic function for scoring a board state based on total number of pieces, mobility (number of moves we can make, number of moves our opponent can make), board weights (positions such as the corners and edges are desirable), and “frontier” pieces, which are particularly vulnerable to capture. For example, here’s the function used to count the number of moves for a given side and current board state:</p>

      <pre><code>
      int Board::countMoves(Side side) {
          int count = 0;
          for (int i = 0; i < BOARD_SIZE; i++) {
              for (int j = 0; j < BOARD_SIZE; j++) {
                  Move move(i, j);
                  if (checkMove(&move, side)) count++;
              }
          }
          return count;
      }
      </code></pre>

      <p>We then moved on to parallelizing the algorithm. The first thing we had to decide was how to parallelize the depth-first search of the decision tree. We chose to start with the PV-split algorithm, and then optimize on top of it.</p>

      <img src="PVSplit.png">

      <p>The PV-split algorithm works by first searching down one branch of the tree on the CPU, and then parallelizing the remaining nodes to be searched on the GPU. This allows the GPU branches to use the bounds from the first CPU-searched branch. Our first attempt to get a working parallel algorithm involved using one block of threads per child node, and then searching down the subtree rooted at that child node with the block. The results from this are summarized in the chart and graph below.</p>

      <img src="Table1.png">
      <br>
      <img src="Graph1.png">

      <h6 align="right"><a href="#top">Back to Top</a></h6>

      <h2>
      <a id="optimizations" class="anchor" href="#optimizations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Optimizations</h2>

      <h5>Dynamic Parallelism of Scoring Game Boards</h5>
      <p>Please see the <a href="https://github.com/xcindylin/CS179-Project/tree/dynamic">dynamic</a> branch of our Github repo.</p>

      <p>One optimization we implemented was using <a href="http://devblogs.nvidia.com/parallelforall/introduction-cuda-dynamic-parallelism/">dynamic parallelism</a> for scoring the game board of a given node. We followed the approach of the serialized version with the exception of the countMoves and getFrontierScore functions which have been replaced by kernels. For example, the following shows the replacement of the countMoves function (as shown above in the <a href="#approach">Approach</a> section) by the cudaCountMovesKernel kernel:</p>

      <pre><code>
      __global__
      void cudaCountMovesKernel(DeviceBoard *board, Side maximizer, int *maximizerScore) {

          unsigned int index = blockDim.x * blockIdx.x + threadIdx.x;
          int maximizerSum = 0;
          while (index < BOARD_SIZE * BOARD_SIZE) {
              int x = index % BOARD_SIZE;
              int y = index / BOARD_SIZE;
              Move move(x, y);
              maximizerSum += board->checkMove(&move, maximizer);
              index += blockDim.x * gridDim.x;
          }

          // warp shuffle reduction
          maximizerSum = warpReduceSum(maximizerSum);
          if (threadIdx.x == 0) {
              *maximizerScore = maximizerSum;
          }
      }
      </code></pre>

      <p>In each kernel, we use <a href="http://devblogs.nvidia.com/parallelforall/faster-parallel-reductions-kepler/">warp shuffle</a> reduction instead of atomicAdd to reduce the serialization of multiple threads adding to the global score variable. Additionally, to minimize the overhead of calling multiple kernels, we wrote the cudaCountMovesKernel kernel shown above to calculate the number of moves for both the maximizer and minimizer with one kernel call.</p>

      <p>We launch our kernels with 1 block of 32 threads to reduce the use of the thread block scheduler of the GPU, which would reduce performance. Finally, to ensure that our kernels run concurrently, we launch our kernels into separate streams. However, actual concurrency of the kernels is not guaranteed [2]. Despite these uncertainties, we were able to see noticeable differences between the GPU speedup factor when using dynamic programming and our naive approach. Specifically, for larger boards and higher depths, dynamic parallelism results in a large speedup in comparison to the naive implementation. This behavior is to be expected since for larger boards / higher depths, we are able to hide the overhead of calling the kernels more since there are more positions on the game board for which to parallelize the computation of the score. The results from dynamic parallelism of the scoring are summarized in the chart and graph below.</p>

      <h6 align="right"><a href="#top">Back to Top</a></h6>

      <h2>
      <a id="gpu-speedup" class="anchor" href="#gpu-speedup" aria-hidden="true"><span class="octicon octicon-link"></span></a>GPU Speedup</h2>
      <p>Each game was played with the following players:</p>
      
      <p>CPU: Player (Black) vs. ExamplePlayer (White)
      <br>GPU: GPUPlayer (Black) vs. ExamplePlayer (White)</p>

      <h5>Board Size: 8 x 8 (Depth 1)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 45
      White score: 19

      Starting GPU game...
      GPU Game completed.
      Black score: 45
      White score: 19

      CPU time: 21.8582 milliseconds
      GPU time: 36.6678 milliseconds
      Speedup factor: 0.596116
      </code></pre>

      <h5>Board Size: 8 x 8 (Depth 2)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 33
      White score: 0

      Starting GPU game...
      GPU Game completed.
      Black score: 33
      White score: 0

      CPU time: 64.9054 milliseconds
      GPU time: 90.4028 milliseconds
      Speedup factor: 0.717958
      </code></pre>

      <h5>Board Size: 8 x 8 (Depth 3)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 45
      White score: 19

      Starting GPU game...
      GPU Game completed.
      Black score: 45
      White score: 19

      CPU time: 493.099 milliseconds
      GPU time: 1149.2 milliseconds
      Speedup factor: 0.429081
      </code></pre>

      <h5>Board Size: 8 x 8 (Depth 4)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 54
      White score: 10

      Starting GPU game...
      GPU Game completed.
      Black score: 54
      White score: 10

      CPU time: 2854.51 milliseconds
      GPU time: 4893.72 milliseconds
      Speedup factor: 0.5833
      </code></pre>

      <h5>Board Size: 8 x 8 (Depth 5)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 56
      White score: 7

      Starting GPU game...
      GPU Game completed.
      Black score: 56
      White score: 7

      CPU time: 45272.3 milliseconds
      GPU time: 35420.2 milliseconds
      Speedup factor: 1.27815
      </code></pre>

      <h5>Board Size: 8 x 8 (Depth 6)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 37
      White score: 0

      Starting GPU game...
      GPU Game completed.
      Black score: 37
      White score: 0

      CPU time: 76664 milliseconds
      GPU time: 98745.8 milliseconds
      Speedup factor: 0.776377
      </code></pre>

      <h5>Board Size: 16 x 16 (Depth 1)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 131
      White score: 125

      Starting GPU game...
      GPU Game completed.
      Black score: 131
      White score: 125

      CPU time: 618.67 milliseconds
      GPU time: 426.073 milliseconds
      Speedup factor: 1.45203
      </code></pre>

      <h5>Board Size: 16 x 16 (Depth 2)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 170
      White score: 86

      Starting GPU game...
      GPU Game completed.
      Black score: 170
      White score: 86

      CPU time: 5400.06 milliseconds
      GPU time: 4884.32 milliseconds
      Speedup factor: 1.10559
      </code></pre>

      <h5>Board Size: 16 x 16 (Depth 3)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 202
      White score: 54

      Starting GPU game...
      GPU Game completed.
      Black score: 202
      White score: 54

      CPU time: 53614.5 milliseconds
      GPU time: 67410.6 milliseconds
      Speedup factor: 0.795342
      </code></pre>

      <h5>Board Size: 32 x 32 (Depth 1)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 586
      White score: 438

      Starting GPU game...
      GPU Game completed.
      Black score: 586
      White score: 438

      CPU time: 25252.4 milliseconds
      GPU time: 6051.52 milliseconds
      Speedup factor: 4.17291
      </code></pre>

      <h5>Board Size: 32 x 32 (Depth 2)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 842
      White score: 182

      Starting GPU game...
      GPU Game completed.
      Black score: 842
      White score: 182

      CPU time: 258019 milliseconds
      GPU time: 181959 milliseconds
      Speedup factor: 1.41801
      </code></pre>

      <h5>Board Size: 64 x 64 (Depth 1)</h5>
      <pre><code>[xlin@mx:~/CS179-Project]> ./testgame 
      Starting CPU game...
      CPU Game completed.
      Black score: 3230
      White score: 866

      Starting GPU game...
      GPU Game completed.
      Black score: 3230
      White score: 866

      CPU time: 788325 milliseconds
      GPU time: 174815 milliseconds
      Speedup factor: 4.50948
      </code></pre>

      <h6 align="right"><a href="#top">Back to Top</a></h6>

      <h2>
      <a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Authors and Contributors</h2>

      <p>Alexandra Cong (<a href="https://github.com/a-cong" class="user-mention">@a-cong</a>) and Cindy Lin (<a href="https://github.com/xcindylin" class="user-mention">@xcindylin</a>)</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/xcindylin/CS179-Project">Parallelizing Alpha-Beta Pruning of Othello Game Decision Trees</a> is maintained by <a href="https://github.com/xcindylin">xcindylin</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>
  </body>
</html>

